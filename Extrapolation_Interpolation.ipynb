{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14d3243",
   "metadata": {},
   "source": [
    "Author: Jonathan Lim \\\n",
    "Date Written: 12 June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfe6a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time\n",
    "from random import random\n",
    "\n",
    "#Plot \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Packages for interpolation \n",
    "from scipy.interpolate import interp1d\n",
    "from scipy import arange, array, exp\n",
    "import scipy\n",
    "\n",
    "#Get File directory\n",
    "import glob\n",
    "\n",
    "#Import Scikit learn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Import function to create training and test set splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import function to automatically create polynomial features (never used)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Import Linear Regression and a regularized regression function (never used)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV, Lasso, Ridge\n",
    "\n",
    "#import function to make a machine learning pipeline (never used)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#Display \n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec7f6c",
   "metadata": {},
   "source": [
    "## *Script Overview:*\n",
    "\n",
    "1) Iterate through Excel Sheets \n",
    "\n",
    "2) Iterate through Country in Excel Sheet \n",
    "\n",
    "3) Interpolate/ Extrapolate Countries with >22 data points (~70% Total Data Points per country) \n",
    "\n",
    "4) For years with values, train_test_split was used to pick out 80% data with least model error (reduce impact of anamolies) \n",
    "\n",
    "5) Determine which degree polynomial to model data (1 < degree < 3), by choosing lowest RMSE\n",
    "\n",
    "6) Where negative values for factor is unintuitive, the predicted value is clipped to 0\n",
    "\n",
    "7) For factor 'WB_FDI_as___of_GNI_', predicted negative value is kept \n",
    "\n",
    "8) Export edited Dataset as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a26858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for \u001b[1m \u001b[91m WB_Mobile_Phone_Subscriptions\u001b[0m.\n",
      "Time taken: \u001b[1m7.154751798999996\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_weighted_tarrifs_\u001b[0m.\n",
      "Time taken: \u001b[1m3.321757809000019\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_FDI_as___of_GNI_\u001b[0m.\n",
      "Time taken: \u001b[1m6.574082147000013\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB___of_taxes_as_part_of_GDP_\u001b[0m.\n",
      "Time taken: \u001b[1m3.340903279000031\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m Societal_Enablement\u001b[0m.\n",
      "Time taken: \u001b[1m4.51494353999999\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m Public_education_expenditure\u001b[0m.\n",
      "Time taken: \u001b[1m1.6352297419999786\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB___Conservation_Area_\u001b[0m.\n",
      "Time taken: \u001b[1m1.6805992500000002\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Number_of_mobile_cellular_subscriptions_per_100\u001b[0m.\n",
      "Time taken: \u001b[1m5.686037747\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Fixed_broadband_subscriptions_per_100_people_\u001b[0m.\n",
      "Time taken: \u001b[1m1.9649378149999848\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Incidence_of_Malaria_per_1000_at_risk_\u001b[0m.\n",
      "Time taken: \u001b[1m1.7339531269999497\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m UN_Proportion_of_seats_held_by_women_in_national_parliaments_(__of_total_number_of_seats)\u001b[0m.\n",
      "Time taken: \u001b[1m2.6532810930000323\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Neonatal_mortality_rate_per_1000_live_births_\u001b[0m.\n",
      "Time taken: \u001b[1m6.280181628000037\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m Hep_B_Incidence_per_100_000\u001b[0m.\n",
      "Time taken: \u001b[1m5.009578874999988\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m UN_Proportion_of_domestic_budget_funded_by_domestic_taxes_(__of_GDP)\u001b[0m.\n",
      "Time taken: \u001b[1m2.2671896470000092\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Gross_School_Enrollment,_primary\u001b[0m.\n",
      "Time taken: \u001b[1m3.7086510269999735\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_People_using_at_least_basic_drinking_water_services_(__of_population)\u001b[0m.\n",
      "Time taken: \u001b[1m1.8145996259999038\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m Water_withdrawals_per_capita_\u001b[0m.\n",
      "Time taken: \u001b[1m0.6906962989999101\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Alchohol_consumption_per_capita_\u001b[0m.\n",
      "Time taken: \u001b[1m1.8472127420000106\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Gini_Index_\u001b[0m.\n",
      "Time taken: \u001b[1m2.217369673999997\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_People_with_basic_handwashing_facilities_including_soap_and_water_(__of_population)\u001b[0m.\n",
      "Time taken: \u001b[1m1.6449338510000189\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Prevelance_of_HIV\u001b[0m.\n",
      "Time taken: \u001b[1m4.51203142199995\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m UN_Labour_share_as___of_GDP\u001b[0m.\n",
      "Time taken: \u001b[1m2.6190224009999383\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m UN_Number_of_people_affected_by_disaster_per_100_000\u001b[0m.\n",
      "Time taken: \u001b[1m1.587957213999971\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m UN_Maternal_Deaths_per_100_000_live_births\u001b[0m.\n",
      "Time taken: \u001b[1m1.982921365999914\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m GHDx_Death_rates_due_to_natural_disasters_\u001b[0m.\n",
      "Time taken: \u001b[1m6.214953854999976\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Firms_with_female_participation_in_ownership_(__of_firms)\u001b[0m.\n",
      "Time taken: \u001b[1m1.7413930760000085\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_People_using_at_least_basic_sanitation_services_(__of_population)\u001b[0m.\n",
      "Time taken: \u001b[1m1.8340968789999579\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB___Undernourishment_\u001b[0m.\n",
      "Time taken: \u001b[1m1.6543176520000316\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Average_transaction_cost_of_sending_remittances_to_a_specific_country_(_)\u001b[0m.\n",
      "Time taken: \u001b[1m1.0560897210000348\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Under_5_mortality_per_1000_live_births_\u001b[0m.\n",
      "Time taken: \u001b[1m5.333233974999985\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_Central_government_debt,_total_(__of_GDP)\u001b[0m.\n",
      "Time taken: \u001b[1m1.8552495349999845\u001b[0m seconds\n",
      "======================================================================\n",
      "Done for \u001b[1m \u001b[91m WB_TB_Incidence_per_100_000\u001b[0m.\n",
      "Time taken: \u001b[1m1.0413755170000059\u001b[0m seconds\n",
      "======================================================================\n",
      "**********************************************************************\n",
      "Full Calculations Done! Time taken: \u001b[1m \u001b[91m97.18516845900001\u001b[0m seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "\n",
    "for excel_directory in lst_excel_directory:\n",
    "    start_time_2 = time.perf_counter()\n",
    "    \n",
    "    #excel name\n",
    "    excel_name = excel_directory.split('/')[-1].replace(' _.xlsx', '').replace('_.xlsx', '').replace('.xlsx', '').replace('.xls', '').replace(' ', '_')\n",
    "\n",
    "    #import file\n",
    "    if excel_directory[-3:] == 'xls':\n",
    "        excel = pd.read_excel(excel_directory)\n",
    "    else:\n",
    "        excel = pd.read_excel(excel_directory, engine='openpyxl')\n",
    "    \n",
    "    #make sure only columns required kept\n",
    "    excel = excel.iloc[:,:5]\n",
    "        \n",
    "    #remove rows without country \n",
    "    excel = excel[~excel['Country Name'].isna()]\n",
    "    # factor column name\n",
    "    col = excel.columns[-1]\n",
    "    #change nd to 0\n",
    "    excel[col] = excel[col].replace('ND',np.nan)\n",
    "    #change string to float\n",
    "    excel[col] = excel[col].astype('float')\n",
    "    #for df later to merge with new extrapolated data \n",
    "    cols = excel.columns[:-1].tolist() \n",
    "    \n",
    "\n",
    "    #create dictionary to combine all dataframe\n",
    "    country_df_list = {}\n",
    "    \n",
    "    iteration = 1\n",
    "    \n",
    "    for country in excel[['Country Name']].drop_duplicates(subset='Country Name').values.tolist():\n",
    "        #create df\n",
    "        df = excel[excel['Country Name'] == country[0]]\n",
    "\n",
    "        #create x and y axis (to plot)\n",
    "        x_data = df['Year'].values.tolist()\n",
    "        \n",
    "        #create df to change (np.nan to 0) #for RMSE and for plotting\n",
    "        df_change_nan = df.copy()\n",
    "        df_change_nan[col] = df_change_nan[col].replace(np.nan,0)\n",
    "        y_data = df_change_nan.loc[:,col].values.tolist() #unnessary unless want to plot\n",
    "\n",
    "        #create df to exclude datapoints without value\n",
    "        df_int_ext = df[~df[col].isna()]\n",
    "\n",
    "        if df_int_ext[[col]].count()[0]<22:\n",
    "            if iteration ==1:\n",
    "                country_df_list['combined_df'] = df\n",
    "                iteration += 1\n",
    "            else:\n",
    "                country_df_list['combined_df'] = country_df_list['combined_df'].append(df)\n",
    "                \n",
    "        elif df_int_ext[[col]].count()[0]>=22:\n",
    "            x_data_interpolate = df_int_ext['Year'].values.tolist()\n",
    "            y_data_interpolate = df_int_ext.loc[:,col].values.tolist()\n",
    "            \n",
    "            #lowest rmse score\n",
    "            lowest_rmse = 100\n",
    "            polynomial_degree = 1\n",
    "\n",
    "            #testing which power has the smallest RMSE is best\n",
    "            for i in range(1,4):\n",
    "                \n",
    "                lowest_error = 10000\n",
    "                random_state_id = 1\n",
    "                for random_rerun in range(0,10):\n",
    "                    #split train test\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(x_data_interpolate, y_data_interpolate, test_size=0.2, random_state = random_rerun)\n",
    "\n",
    "                    #training model\n",
    "                    poly_fit = np.poly1d(np.polyfit(X_train,y_train,i))\n",
    "\n",
    "                    #test model\n",
    "                    predicted_y = poly_fit(X_test) \n",
    "                    error=np.mean((predicted_y-y_test)**2)\n",
    "\n",
    "                    if error < lowest_error:\n",
    "                        lowest_error = error\n",
    "                        random_state_id = iteration\n",
    "                \n",
    "                #use these X-train with lowest error\n",
    "                X_train, X_test, y_train, y_test = train_test_split(x_data_interpolate, y_data_interpolate, test_size=0.2, random_state = random_state_id)\n",
    "            \n",
    "                #polynomial fit\n",
    "                poly_fit = np.poly1d(np.polyfit(X_train,y_train,i))\n",
    "\n",
    "                other_x = np.array(x_data) #create array for x-axis\n",
    "                other_y = poly_fit(other_x) #extrapolate/ interpolate y-axis\n",
    "               \n",
    "                #Calculated RMSE\n",
    "                rmse = np.sqrt(mean_squared_error(y_data,other_y))\n",
    "            \n",
    "                if rmse < lowest_rmse:\n",
    "                    lowest_rmse = rmse\n",
    "                    polynomial_degree = i\n",
    "            \n",
    "\n",
    "            #Generate polynomial model\n",
    "            poly_fit = np.poly1d(np.polyfit(X_train,y_train,polynomial_degree))\n",
    "\n",
    "            other_x = np.array(x_data) #create array for x-axis\n",
    "            other_y = poly_fit(other_x) #extrapolate/ interpolate y-axis\n",
    "            \n",
    "            if excel_name == 'WB_FDI_as___of_GNI_':\n",
    "                pass\n",
    "            else:\n",
    "                #ground negative values to zero \n",
    "                other_y = other_y.clip(min=0) \n",
    "\n",
    "            #df containing Year & Factor\n",
    "            fill_data_df = pd.DataFrame(np.hstack((other_x[:,None],other_y[:,None]))).rename(columns = {0:'Year',1:col})\n",
    "\n",
    "            #merge based on Year to form new df of data\n",
    "            new_data_df = df[cols].merge(fill_data_df, how='left', on='Year')\n",
    "            \n",
    "            if iteration ==1:\n",
    "                country_df_list['combined_df'] = new_data_df\n",
    "                iteration +=1\n",
    "            else:\n",
    "                country_df_list['combined_df'] = country_df_list['combined_df'].append(new_data_df)\n",
    "                 \n",
    "\n",
    "    #export file \n",
    "    country_df_list['combined_df'].to_csv('/Users/jonathanlim/Coding/Mannat/output_data/'+ excel_name + '_edited.csv')\n",
    "    \n",
    "    #inform\n",
    "    print(f'Done for \\033[1m \\033[91m {excel_name}\\033[0m.')\n",
    "    print(f\"Time taken: \\033[1m{time.perf_counter()- start_time_2}\\033[0m seconds\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "print(\"*\"*70)\n",
    "print(f'\\033[92m\\033[1mFull Calculations Done!\\033[0m Time taken: \\033[1m \\033[91m{time.perf_counter()- start}\\033[0m seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd3824",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2abe2709",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df = pd.read_csv('/Users/jonathanlim/Coding/Mannat/output_data/WB_Mobile_Phone_Subscriptions_edited.csv')\n",
    "\n",
    "#Plot graph for country new data\n",
    "for country in check_df[['Country Name']].drop_duplicates(subset='Country Name').values.tolist():\n",
    "    country_df = check_df[check_df['Country Name'] == country[0]]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f'Trend for {country[0]}')\n",
    "    plt.plot(country_df['Year'].tolist(),country_df['Mobile Phone Subscriptions %'].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
